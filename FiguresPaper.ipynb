{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#activate r magic\n",
    "%load_ext rpy2.ipython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utilities as UT\n",
    "import missingno as msno\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import gc\n",
    "\n",
    "random.seed(1976)\n",
    "np.random.seed(1976)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Anaylsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "#Image(filename='images/Picture 1.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"Figures/Slide1.jpeg\" width=\"800\" height=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of gene to desc\n",
    "#from the gff file\n",
    "def make_desc(_GFF=os.path.join('genomes','tb927_3','tb927_3.gff')):\n",
    "\n",
    "    gff =pd.read_csv( _GFF, sep='\\t', header=None, comment='#')\n",
    "    \n",
    "    gff = gff[gff.iloc[:,2]=='gene']\n",
    "    #print( gff[gff[gff.columns[-1]].str.contains('Tb427_020006200')] )\n",
    "    desc = {}\n",
    "    for n in gff.iloc[:,-1]:\n",
    "        n=n.replace('%2C',' ')\n",
    "        item_list = n.split(';')\n",
    "        #print (item_list)\n",
    "        temp_dict = {}\n",
    "        for m in item_list:\n",
    "            #print(m)\n",
    "            temp_dict[m.split('=')[0].strip()]=m.split('=')[1].strip()\n",
    "        #print(temp_dict['ID'])\n",
    "        #print(temp_dict['description'])\n",
    "        desc[temp_dict['ID']]=temp_dict.get('description','none')\n",
    "    return desc\n",
    "\n",
    "desc_dict = make_desc('InData/tb927_3.gff')\n",
    "desc_dict['Tb10.v4.0073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('InData/tb927_3_ks_counts_final.txt',index_col=[0],comment='#',sep='\\t')\n",
    "data_col = df.columns[6:25]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col = df.columns[5:]\n",
    "data_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = df[data_col]\n",
    "indata.columns = [n.split('/')[0] for  n in indata.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata=indata.dropna()\n",
    "#indata.loc['KS17gene_1749a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC - Corr analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(14,12))\n",
    "cbar_ax = fig.add_axes([.91, .6, .03, .2])\n",
    "sns.heatmap(np.log2(indata).corr(),\n",
    "            #vmin=-1,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,linewidths=.5,ax=ax, cbar_ax = cbar_ax, cbar=True)\n",
    "print(ax.get_ylim())\n",
    "ax.set_ylim(18,0.1)\n",
    "plt.savefig('Figures/Figure_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC - MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "palette = ['r']*9+['b']*9\n",
    "fig,ax = plt.subplots(figsize=(8,8), ncols=1, nrows=1)\n",
    "UT.make_mds(np.log2(indata),palette,ax,color_dictionary={'r':'BSF','b':'PCF'})\n",
    "plt.savefig('Figures/Figure_3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Length and GC content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_ids(n):\n",
    "    res = {}\n",
    "    temp = n.split(';')\n",
    "    temp =[n.strip() for n in temp if len(n)>2]\n",
    "    for f in temp:\n",
    "        key = f.split(' ')[0]\n",
    "        value = f.split(' ')[1]\n",
    "        key=key.replace('\\\"','').replace('\\'','').strip()\n",
    "        value=value.replace('\\\"','').replace('\\'','').strip()\n",
    "        res[key]=value\n",
    "    return res['gene_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_content = pd.read_csv('InData/GC_content_927.txt',sep='\\t')\n",
    "gc_content = gc_content[gc_content['8_usercol']=='transcript']\n",
    "gc_content['gene_id'] = [get_gene_ids(n) for n in gc_content['10_usercol']]\n",
    "gc_content = gc_content.drop_duplicates('gene_id')\n",
    "gc_content.set_index('gene_id',inplace=True)\n",
    "gc_content=gc_content[['19_seq_len','12_pct_gc']]\n",
    "gc_content.columns = ['length', 'gccontent']\n",
    "gc_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indata.shape)\n",
    "indata=indata.join(gc_content,how='inner')\n",
    "gc_content = gc_content[['length', 'gccontent']]\n",
    "indata.drop(['length', 'gccontent'],axis=1,inplace=True) \n",
    "indata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_rpkm = indata.sum()/1000000\n",
    "indata_rpkm = indata.divide(scale_rpkm,axis=1)\n",
    "indata_rpkm=indata_rpkm.join(gc_content,how='left')\n",
    "indata_rpkm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = indata_rpkm['length']\n",
    "indata_rpkm.drop(['length','gccontent'],inplace=True,axis=1)\n",
    "indata_rpkm=indata_rpkm.divide(length/1000,axis=0)\n",
    "indata_rpkm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata_rpkm['B_tot'] = indata_rpkm[['B_tot_1','B_tot_2','B_tot_3']].median(axis=1)\n",
    "indata_rpkm['P_tot'] = indata_rpkm[['P_tot_1','P_tot_2','P_tot_3']].median(axis=1)\n",
    "indata_rpkm['B_sub'] = indata_rpkm[['B_sub_1','B_sub_2','B_sub_3']].median(axis=1)\n",
    "indata_rpkm['P_sub'] = indata_rpkm[['P_sub_1','P_sub_2','P_sub_3']].median(axis=1)\n",
    "indata_rpkm['B_pol'] = indata_rpkm[['B_pol_1','B_pol_2','B_pol_3']].median(axis=1)\n",
    "indata_rpkm['P_pol'] = indata_rpkm[['P_pol_1','P_pol_2','P_pol_3']].median(axis=1)\n",
    "#indata_rpkm = indata_rpkm[['B_tot','B_sub','B_pol','P_tot','P_sub','P_pol']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TryTripDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trypdb =pd.read_csv('InData/RNA_dataset.txt',sep='\\t')\n",
    "trypdb.columns = list(trypdb.columns[0:5])+['PCF1','BSF1','PCF2','BSF2','BSF3','PCF3','BSF4','drop']\n",
    "trypdb.drop(['drop','Organism'],axis=1,inplace=True)\n",
    "trypdb.set_index('Gene ID',inplace=True)\n",
    "trypdb=trypdb.join(indata_rpkm,how='inner')\n",
    "print(trypdb.shape)\n",
    "trypdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trypdb.iloc[:,3:]=np.log10(trypdb.iloc[:,3:])\n",
    "trypdb=trypdb.replace(np.inf,np.nan).replace(-np.inf,np.nan).dropna()\n",
    "print(trypdb.shape)\n",
    "trypdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig,axes=plt.subplots(ncols=3,nrows=2,figsize=(12,8))\n",
    "x='BSF1'\n",
    "y='BSF2'\n",
    "ax=axes[0,0]\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[0,1]\n",
    "x='BSF1'\n",
    "y='BSF3'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[0,2]\n",
    "x='BSF1'\n",
    "y='BSF4'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[1,0]\n",
    "x='BSF2'\n",
    "y='BSF3'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[1,1]\n",
    "x='BSF2'\n",
    "y='BSF4'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[1,2]\n",
    "x='BSF3'\n",
    "y='BSF4'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Figure_8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig,axes=plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "\n",
    "ax=axes[0]\n",
    "x='PCF1'\n",
    "y='PCF2'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[1]\n",
    "x='PCF1'\n",
    "y='PCF3'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[2]\n",
    "x='PCF2'\n",
    "y='PCF3'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Figure_9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use('ggplot')\n",
    "fig,axes=plt.subplots(ncols=4,nrows=1,figsize=(16,4))\n",
    "\n",
    "ax=axes[0]\n",
    "x='B_tot_1'\n",
    "y='BSF1'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[1]\n",
    "x='B_tot_1'\n",
    "y='BSF2'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "ax=axes[2]\n",
    "x='B_tot_1'\n",
    "y='BSF3'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "\n",
    "ax=axes[3]\n",
    "x='B_tot_1'\n",
    "y='BSF4'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,4))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Figure_10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig,axes=plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "\n",
    "ax=axes[0]\n",
    "x='P_tot_1'\n",
    "y='PCF1'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,3))\n",
    "\n",
    "\n",
    "ax=axes[1]\n",
    "x='P_tot_1'\n",
    "y='PCF2'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,3))\n",
    "\n",
    "\n",
    "ax=axes[2]\n",
    "x='P_tot_1'\n",
    "y='PCF3'\n",
    "trypdb.plot(kind='scatter',x=x,y=y,alpha=0.1,ax=ax)\n",
    "UT.plot_line(trypdb[x], trypdb[y], ax, limits=(0,3))\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Figure_11.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edgeR to filter low counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i indata\n",
    "options(warn=-1)\n",
    "library(\"limma\") \n",
    "library(\"edgeR\")\n",
    "head(indata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "group <- factor(c(\n",
    "    'Btot','Btot','Btot',\n",
    "    'Bpol','Bpol','Bpol',\n",
    "    'Bsub','Bsub','Bsub',\n",
    "    'Ptot','Ptot','Ptot',\n",
    "    'Ppol','Ppol','Ppol',\n",
    "    'Psub','Psub','Psub'))\n",
    "\n",
    "y <- DGEList(counts=indata,group=group)\n",
    "keep <- filterByExpr(y)\n",
    "y <- y[keep,,keep.lib.sizes=FALSE]\n",
    "counts = y$counts\n",
    "genes = row.names(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o counts,genes\n",
    "indata = pd.DataFrame(counts,index=genes,columns=indata.columns)\n",
    "indata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata=indata.join(gc_content,how='inner')\n",
    "indata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GC / length content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_content = indata[['length', 'gccontent']]\n",
    "indata.drop(['length', 'gccontent'],axis=1,inplace=True)\n",
    "print(indata.shape,gc_content.shape)\n",
    "indata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### size factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeFactors=indata.sum()\n",
    "sizeFactors = sizeFactors.values\n",
    "sizeFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.log2(gc_content['length']/1000).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i gc_content,indata,sizeFactors\n",
    "library(cqn)\n",
    "library(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "stopifnot(all(rownames(indata) == rownames(gc_content)))\n",
    "cqn.subset <- cqn(indata, lengths = gc_content$length,\n",
    "                  x = gc_content$gccontent, sizeFactors = sizeFactors,\n",
    "                  verbose = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R cqn.subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "cqnplot <- function(x, n = 1, col = \"grey60\", ylab=\"estimated bias effect\", \n",
    "                    xlab = \"\", type = \"l\", lty = 1, ...) {\n",
    "    if(class(x) != \"cqn\")\n",
    "        stop(\"'x' needs to be of class 'cqn'\")\n",
    "    if(n == 1) {\n",
    "        func <- x$func1\n",
    "        grid <- x$grid1\n",
    "        knots <- x$knots1\n",
    "    }\n",
    "    if(n == 2) {\n",
    "        if(is.null(x$func2))\n",
    "            stop(\"argument 'x' does not appear to have two smooth functions (component 'func2' is NULL)\")\n",
    "        func <- x$func2\n",
    "        grid <- x$grid2\n",
    "        knots <- x$knots2\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #par(mar=c(5.1, 4.1, 4.1, 8.1), xpd=TRUE)\n",
    "    matplot(replicate(ncol(func), grid), func, ylab = ylab, xlab = xlab, type = type,\n",
    "            col = col, lty = lty, ...)\n",
    "    \n",
    "    legend(\"bottomleft\", legend = colnames(x$counts), inset=c(1,0),\n",
    "           title=\"Samples\", lty = lty, col = col)\n",
    "    rug(knots, lwd = 2)\n",
    "    invisible(x)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "library(repr)\n",
    "#options(repr.plot.width = 10, repr.plot.height = 0.75)\n",
    "# Change plot size to 4 x 3\n",
    "#options(repr.plot.width=4, repr.plot.height=3)\n",
    "\n",
    "\n",
    "colors <- c(\n",
    "    'grey','grey','grey',\n",
    "    'green','green','green',\n",
    "    'blue','blue','blue',\n",
    "    'grey','grey','grey',\n",
    "    'green','green','green',\n",
    "    'blue','blue','blue'\n",
    "           )\n",
    "lty =c(1,1,1,1,1,1,1,1,1,\n",
    "       2,2,2,2,2,2,2,2,2)\n",
    "\n",
    "png(\"Figures/Figure_12.png\")\n",
    "#par(mfrow=c(1,2))\n",
    "cqnplot(cqn.subset, col=colors,\n",
    "        n = 1, xlab = \"GC content\", lty = lty,\n",
    "        ylim = c(1,12), \n",
    "        \n",
    "\n",
    "       )\n",
    "dev.off()\n",
    "\n",
    "#ggsave('plot.png', width=8.27, height= 11.69) #A4 size in inches\n",
    "#dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(repr)\n",
    "#options(repr.plot.width = 12, repr.plot.height = 0.75)\n",
    "# Change plot size to 4 x 3\n",
    "#options(repr.plot.width=8, repr.plot.height=3)\n",
    "\n",
    "\n",
    "colors <- c(\n",
    "    'grey','grey','grey',\n",
    "    'green','green','green',\n",
    "    'blue','blue','blue',\n",
    "    'grey','grey','grey',\n",
    "    'green','green','green',\n",
    "    'blue','blue','blue'\n",
    "           )\n",
    "lty =c(1,1,1,1,1,1,1,1,1,\n",
    "       2,2,2,2,2,2,2,2,2)\n",
    "\n",
    "#par(mfrow=c(1,2))\n",
    "png(\"Figures/Figure_13.png\")\n",
    "cqnplot(cqn.subset, col=colors,\n",
    "        n = 2, xlab = \"length\", lty = lty,\n",
    "        ylim = c(-5,16), \n",
    "    \n",
    "       )\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "RPKM.cqn <- cqn.subset$y + cqn.subset$offset\n",
    "out_table <- RPKM.cqn\n",
    "head(out_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o out_table\n",
    "out_table = pd.DataFrame(out_table,index=indata.index.values,columns=indata.columns)\n",
    "out_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Normalized Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(figsize=(16,4),ncols=2)\n",
    "ax = axes[0]\n",
    "out_table.plot(kind='box',ax=ax,rot=90,showfliers=False)\n",
    "\n",
    "ax = axes[1]\n",
    "out_table.replace(-np.inf,-1.5).plot(kind='hist',\n",
    "                                            histtype='step',\n",
    "                                            bins=100,ax=ax)\n",
    "UT.hist_legend(ax,'Sample')\n",
    "#ax.set_xticklabels(out_df.columns, rotation=90, )\n",
    "plt.show()\n",
    "print(out_table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Expression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(edgeR)\n",
    "# Make groups\n",
    "design_with_all <- model.matrix( ~0+group )\n",
    "\n",
    "y <- DGEList(counts=indata, \n",
    "                  lib.size = sizeFactors,\n",
    "                  group = group, \n",
    "                  )\n",
    "\n",
    "y$offset <- cqn.subset$glm.offset\n",
    "# Estimate dispersion\n",
    "y <- estimateGLMCommonDisp( y, design_with_all )\n",
    "y <- estimateGLMTrendedDisp( y, design_with_all )\n",
    "y <- estimateGLMTagwiseDisp( y, design_with_all )\n",
    "# Fit counts to model\n",
    "fit_all <- glmFit( y, design_with_all )\n",
    "contrast_Bpol_v_Bsub <- glmLRT( fit_all, contrast=makeContrasts( groupBpol-groupBsub,\n",
    "                                                                levels=design_with_all ) )\n",
    "\n",
    "table_Bpol_v_Bsub <- topTags(contrast_Bpol_v_Bsub, n=Inf, \n",
    "                             sort.by = \"none\", adjust.method=\"BH\")$table\n",
    "topTags( contrast_Bpol_v_Bsub, n=5 )\n",
    "head(table_Bpol_v_Bsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "contrast_Ppol_v_Psub <- glmLRT( fit_all, contrast=makeContrasts(groupPpol-groupPsub,\n",
    "                                                                levels=design_with_all ) )\n",
    "\n",
    "table_Ppol_v_Psub <- topTags(contrast_Ppol_v_Psub, n=Inf, sort.by = \"none\", adjust.method=\"BH\")$table\n",
    "topTags( contrast_Ppol_v_Psub, n=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o table_Ppol_v_Psub\n",
    "table_Ppol_v_Psub['log_PValue'] = -np.log10(table_Ppol_v_Psub['PValue'])\n",
    "table_Ppol_v_Psub['log_FDR'] = -np.log10(table_Ppol_v_Psub['FDR'])\n",
    "table_Ppol_v_Psub['desc']=[desc_dict.get(n,'none') for n in table_Ppol_v_Psub.index.values]\n",
    "table_Ppol_v_Psub.to_csv('Tables/Table_5.csv')\n",
    "table_Ppol_v_Psub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o table_Bpol_v_Bsub\n",
    "table_Bpol_v_Bsub.head()\n",
    "table_Bpol_v_Bsub['log_PValue'] = -np.log10(table_Bpol_v_Bsub['PValue'])\n",
    "table_Bpol_v_Bsub['log_FDR'] = -np.log10(table_Bpol_v_Bsub['FDR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_Bpol_v_Bsub['desc']=[desc_dict.get(n,'none') for n in table_Bpol_v_Bsub.index.values]\n",
    "table_Bpol_v_Bsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_Bpol_v_Bsub.to_csv('Tables/Table_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRP10 Tb927.8.2780\n",
    "#https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5568443/\n",
    "#table_Bpol_v_Bsub.loc['KS17gene_1749a'],table_Ppol_v_Psub.loc['KS17gene_1749a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grumpy\n",
    "#https://www.biorxiv.org/content/10.1101/2020.05.03.074625v1\n",
    "#table_Bpol_v_Bsub.loc['KS17gene_3137a'],table_Ppol_v_Psub.loc['KS17gene_3137a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1006279\n",
    "#'Tb927.11.14220'\n",
    "#table_Bpol_v_Bsub.loc['KS17gene_4295a'],table_Ppol_v_Psub.loc['KS17gene_4295a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_Bpol_v_Bsub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_lncRNA = open('InData/GS_gene_list.txt').read().split('\\n')\n",
    "def grampy_VolcanoPlot(table,title,ax=False,ksgene='KS17gene_3137a',xlims=False):\n",
    "    plt.style.use('ggplot')\n",
    "    if not ax:\n",
    "        fig,ax=plt.subplots(figsize=(12,6))\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    table.plot(x='logFC',y='log_FDR',kind='scatter',s=5,alpha=0.2,ax=ax,c='black',label='the rest')\n",
    "    \n",
    "    temp = [n for n in ks_lncRNA if n in table.index.values]\n",
    "    table.loc[temp].plot(x='logFC',y='log_FDR',kind='scatter',s=10,alpha=1,c='b',ax=ax,\n",
    "                              label='lncRNA')\n",
    "    \n",
    "    \n",
    "    table.loc[[ksgene]].plot(y='log_FDR',x='logFC',kind='scatter',ax=ax,s=50, alpha=1\n",
    "                                                   ,c='r',label='Grumpy')\n",
    "    \n",
    "    lgnd= ax.legend()\n",
    "    lgnd.legendHandles[0]._sizes = [20]\n",
    "    lgnd.legendHandles[1]._sizes = [20]\n",
    "    lgnd.legendHandles[2]._sizes = [20]\n",
    "    if xlims:\n",
    "        ax.set_xlim(xlims[0],xlims[1])\n",
    "\n",
    "def grampy_MAplot(table,title,ksgene='KS17gene_3137a'):\n",
    "    plt.style.use('ggplot')\n",
    "    fig,ax=plt.subplots(figsize=(12,6))\n",
    "    ax.set_title(title)\n",
    "    table.plot(x='logCPM',y='logFC',kind='scatter',s=5,alpha=0.2,ax=ax,c='black',label='the rest')\n",
    "    temp = [n for n in ks_lncRNA if n in table.index.values]\n",
    "    table.loc[temp].plot(x='logCPM',y='logFC',kind='scatter',s=10,alpha=1,c='b',ax=ax,\n",
    "                             label='lncRNA')\n",
    "    table.loc[[ksgene]].plot(y='logFC',x='logCPM',kind='scatter',ax=ax,s=50, alpha=1\n",
    "                                                   ,c='r',label='Grumpy')\n",
    "    lgnd= ax.legend()\n",
    "    for i,n in enumerate(lgnd.legendHandles):\n",
    "        n._sizes = [20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(figsize=(12,12),nrows=2)\n",
    "grampy_VolcanoPlot(table_Bpol_v_Bsub,'BSF',axes[0],xlims=(-8,8))\n",
    "grampy_VolcanoPlot(table_Ppol_v_Psub,'PCF',axes[1],xlims=(-8,8))\n",
    "UT.set_fig_label(axes[0],'A')\n",
    "UT.set_fig_label(axes[1],'B')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Figure_19.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(figsize=(12,12),nrows=2)\n",
    "grampy_VolcanoPlot(table_Bpol_v_Bsub,'BSF',axes[0],'KS17gene_1749a')\n",
    "grampy_VolcanoPlot(table_Ppol_v_Psub,'PCF',axes[1],'KS17gene_1749a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average subpolysome/polysome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "contrast_pol_v_sub <- glmLRT( fit_all, contrast=makeContrasts((groupPsub+groupBsub)/2-(groupPpol+groupBpol)/2,\n",
    "                                                                levels=design_with_all ) )\n",
    "\n",
    "table_pol_v_sub <- topTags(contrast_pol_v_sub, n=Inf, sort.by = \"none\", adjust.method=\"BH\")$table\n",
    "topTags( contrast_pol_v_sub, n=20 )\n",
    "#head(contrast_pol_v_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o table_pol_v_sub\n",
    "table_pol_v_sub.head()\n",
    "table_pol_v_sub['log_PValue'] = -np.log10(table_pol_v_sub['PValue'])\n",
    "table_pol_v_sub['log_FDR'] = -np.log10(table_pol_v_sub['FDR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_pol_v_sub.loc['KS17gene_1749a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grampy_VolcanoPlot(table_pol_v_sub,'SUB/POL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grampy_MAplot(table_pol_v_sub,'SUB/POL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pol_v_sub.loc['KS17gene_4295a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_pol_v_sub.plot(kind='scatter',x='logCPM',y='logFC',alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "design_anova <- model.matrix(~group, data=y$samples)\n",
    "fit <- glmQLFit(y, design_anova)\n",
    "qlf <- glmQLFTest(fit, coef=2:6)\n",
    "anova_like <- topTags(qlf, n=Inf, sort.by = \"none\", adjust.method=\"BH\")$table\n",
    "head(anova_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o anova_like\n",
    "anova_like=anova_like[['F', 'PValue', 'FDR']]\n",
    "anova_threshold = 1e-2\n",
    "anova_like.shape,anova_like[anova_like['FDR']<anova_threshold].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%R\n",
    "#library(HybridMTest)\n",
    "#computed but not used for now\n",
    "#anova_test <- row.oneway.anova(cpm_df, group)\n",
    "#FDR1 <- p.adjust(anova_test$pval, \"bonferroni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%R -o cpm_df,anova_test,FDR1,tt_Bsub_Bpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%R length(FDR1[FDR1 < 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RadViz - Signature in BSF SUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "#from cqn These values are on the log2scale.        \n",
    "radviz_dataset = np.exp(out_df).copy()\n",
    "\n",
    "radviz_dataset=radviz_dataset[anova_like['FDR']<anova_threshold]\n",
    "cols = list(radviz_dataset.columns)\n",
    "#group coluns in cunk of 3 to compute the mean\n",
    "col_grups = chunks(cols, 3)\n",
    "for g in col_grups:\n",
    "    base = '_'.join(g[0].split('_')[0:2])\n",
    "    radviz_dataset[base]=radviz_dataset[g].median(axis=1)\n",
    "\n",
    "#assign each gene to the class with max count\n",
    "\n",
    "classes = radviz_dataset.iloc[:,18:].idxmax(axis=1)\n",
    "#replace = {'B_pol':0, 'B_sub':1, 'B_tot':2, 'P_pol':3, 'P_sub':4, 'P_tot':5}\n",
    "#classes = classes.replace(replace)\n",
    "radviz_dataset=radviz_dataset.iloc[:,18:]\n",
    "radviz_dataset['classes']=classes\n",
    "radviz_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radviz_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RadViz figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,12))\n",
    "cols = [n for n in out_df.columns if n.endswith('_mean')]\n",
    "color = {'B_tot':'tab:purple','B_pol':'tab:green','B_sub':'tab:blue',\n",
    "         'P_tot':'tab:brown','P_pol':'tab:red','P_sub':'tab:orange'}\n",
    "\n",
    "radviz_dataset=radviz_dataset[['B_tot','P_tot','B_sub','P_sub','B_pol','P_pol','classes']]\n",
    "rad_viz,to_plot,s = UT.radviz(radviz_dataset, \n",
    "                           'classes', color=color,ax=ax,)\n",
    "plt.savefig('Figures/Figure_14.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mydata = out_df.iloc[:,:18]\n",
    "#min_values = []\n",
    "#for col in mydata:\n",
    "#    min_values.append(mydata[col][mydata[col]>0].min())\n",
    "#min_values\n",
    "#del mydata\n",
    "\n",
    "\n",
    "cluster_dataset=np.exp(out_df.iloc[:,:18])#+min_values\n",
    "cluster_dataset.head()\n",
    "cluster_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%R -o anova_test,FDR\n",
    "cluster_dataset=out_df.iloc[:,:18]\n",
    "clustergrid = sns.clustermap(cluster_dataset[anova_like['FDR']<anova_threshold].sample(frac=0.3),\n",
    "                             cmap=sns.color_palette(\"coolwarm\", 256), \n",
    "                             standard_scale=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "plt.style.use('ggplot')\n",
    "X = UT.standard_scale(cluster_dataset[anova_like['FDR']<anova_threshold],0)\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans()\n",
    "fig, ax = plt.subplots(figsize=(8,8)) \n",
    "visualizer = KElbowVisualizer(model, k=(2,12),ax=ax)\n",
    "\n",
    "visualizer.fit(X.values)        # Fit the data to the visualizer\n",
    "\n",
    "\n",
    "visualizer.show(outpath=\"Figures/Figure_15.png\")\n",
    "#visualizer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "pd.Series(kmeans.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cluster import SpectralBiclustering\n",
    "\n",
    "#clustering = SpectralBiclustering(n_clusters=5,\n",
    "#assign_labels=\"discretize\",\n",
    "#random_state=0).fit(X)\n",
    "#pd.Series(clustering.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(order)\n",
    "#dict_replace = dict(zip(order,[1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = TDdf[anova_test['FDR']<0.01]\n",
    "X['label']=kmeans.labels_+1\n",
    "#X['label']=X['label'].replace(dict_replace)\n",
    "order = pd.Series(kmeans.labels_).value_counts().index.values\n",
    "\n",
    "list_df = []\n",
    "for n in order:\n",
    "    list_df.append(X[X['label']==n+1])\n",
    "\n",
    "final_list_df = []\n",
    "for index,temp_df in enumerate(list_df):\n",
    "    temp_df['label']=index+1\n",
    "    final_list_df.append(temp_df)\n",
    "    \n",
    "\n",
    "X = pd.concat(final_list_df)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))  \n",
    "cbar_ax = fig.add_axes([.91, .6, .03, .2])\n",
    "# Sample figsize in inches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(X.iloc[:,0:-1].T.iloc[\n",
    "    clustergrid.dendrogram_col.reordered_ind].T.astype(float),\n",
    "            cmap=sns.color_palette(\"coolwarm\", 3),\n",
    "           ax=ax, cbar_ax = cbar_ax, cbar=True)\n",
    "\n",
    "plt.savefig('Figures/Figure_16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sort_values(['label']).drop_duplicates('label')['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(X['label'].unique())\n",
    "X.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,10),nrows=4)\n",
    "\n",
    "for c in [1,2,3,4]:\n",
    "    \n",
    "    #print(c,c-1)\n",
    "    b=c-1\n",
    "    sns.heatmap(X[X['label']==c].iloc[:,0:-1].T.iloc[\n",
    "    clustergrid.dendrogram_col.reordered_ind].T.astype(float),\n",
    "    cmap=sns.color_palette(\"coolwarm\", 3),\n",
    "    ax=axes[b])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_lncRNA = open('InData/GS_gene_list.txt').read().split('\\n')\n",
    "X['is_ks']=[1 if n in ks_lncRNA else 0 for n in X.index.values]\n",
    "len(ks_lncRNA)\n",
    "X['is_ks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table lncRNA enrichment in clusters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "#k = np.arange(5)\n",
    "#N = 52 # population size\n",
    "#G = 4  # number of good elements in population\n",
    "#n = 5  # simple random sample size\n",
    "#stats.hypergeom.pmf(k, N, G, n)\n",
    "\n",
    "population_size = X.shape[0]\n",
    "\n",
    "for n in [1,2,3,4]:\n",
    "    sample_size = X[X['label']==n].shape[0]\n",
    "    sample_sucess = X[(X['label']==n) & (X['is_ks']==1) ].shape[0]\n",
    "    population_sucess = X[X['is_ks']==1].shape[0]\n",
    "    #print(n, sample_sucess, sample_size, population_sucess, population_size)\n",
    "    print('cluster {n}: enrichment pvalue={pval:.2e}'.format(n=n, pval =stats.hypergeom.pmf(sample_sucess, \n",
    "                                 population_size, \n",
    "                                 population_sucess, \n",
    "                                 sample_size)))\n",
    "        \n",
    "    #avg_value = cluster_dataset.loc[X[(X['label']==n)].index.values][\n",
    "    #    ['BSF-PCF-1','BSF-PCF-2','BSF-PCF-3']].median(axis=1).median()\n",
    "    #print(np.log2(avg_value))\n",
    "    print('_________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X['desc']=[desc_dict.get(n,'none') for n in X.index.values]\n",
    "X['H/ACA-like snoRNA']=[1 if 'H/ACA-like snoRNA' in n else 0 for n in X['desc']]\n",
    "X['snoRNA']=[1 if 'snoRNA' in n else 0 for n in X.index.values]\n",
    "X['Noncoding']=[1 if 'Noncoding RNA' in n else 0 for n in X['desc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table snoRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby('label')['snoRNA','H/ACA-like snoRNA','is_ks'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('Tables/Table_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [1,2,3,4]:\n",
    "    sample_size = X[X['label']==n].shape[0]\n",
    "    sample_sucess = X[(X['label']==n) & (X['H/ACA-like snoRNA']==1) ].shape[0]\n",
    "    population_sucess = X[X['H/ACA-like snoRNA']==1].shape[0]\n",
    "    #print(n, sample_sucess, sample_size, population_sucess, population_size)\n",
    "    print('cluster {n}: enrichment pvalue={pval:.2e}'.format(n=n, pval =stats.hypergeom.pmf(sample_sucess, \n",
    "                                 population_size, \n",
    "                                 population_sucess, \n",
    "                                 sample_size)))\n",
    "        \n",
    "    #avg_value = cluster_dataset.loc[X[(X['label']==n)].index.values][\n",
    "    #    ['BSF-PCF-1','BSF-PCF-2','BSF-PCF-3']].median(axis=1).median()\n",
    "    #print(np.log2(avg_value))\n",
    "    print('_________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [1,2,3,4]:\n",
    "    sample_size = X[X['label']==n].shape[0]\n",
    "    sample_sucess = X[(X['label']==n) & (X['snoRNA']==1) ].shape[0]\n",
    "    population_sucess = X[X['snoRNA']==1].shape[0]\n",
    "    #print(n, sample_sucess, sample_size, population_sucess, population_size)\n",
    "    print('cluster {n}: enrichment pvalue={pval:.2e}'.format(n=n, pval =stats.hypergeom.pmf(sample_sucess, \n",
    "                                 population_size, \n",
    "                                 population_sucess, \n",
    "                                 sample_size)))\n",
    "        \n",
    "    #avg_value = cluster_dataset.loc[X[(X['label']==n)].index.values][\n",
    "    #    ['BSF-PCF-1','BSF-PCF-2','BSF-PCF-3']].median(axis=1).median()\n",
    "    #print(np.log2(avg_value))\n",
    "    print('_________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [1,2,3,4]:\n",
    "    sample_size = X[X['label']==n].shape[0]\n",
    "    sample_sucess = X[(X['label']==n) & (X['Noncoding']==1) ].shape[0]\n",
    "    population_sucess = X[X['Noncoding']==1].shape[0]\n",
    "    #print(n, sample_sucess, sample_size, population_sucess, population_size)\n",
    "    print('cluster {n}: enrichment pvalue={pval:.2e}'.format(n=n, pval =stats.hypergeom.pmf(sample_sucess, \n",
    "                                 population_size, \n",
    "                                 population_sucess, \n",
    "                                 sample_size)))\n",
    "        \n",
    "    #avg_value = cluster_dataset.loc[X[(X['label']==n)].index.values][\n",
    "    #    ['BSF-PCF-1','BSF-PCF-2','BSF-PCF-3']].median(axis=1).median()\n",
    "    #print(np.log2(avg_value))\n",
    "    print('_________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GO term Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goatools.base import download_go_basic_obo\n",
    "from goatools.associations import read_associations\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.associations import read_gaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix gaf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "replace_dict = {'P':'BP','F':'MF','C':'CC'}\n",
    "def pars_trytripDB_gaf(infile):\n",
    "    new_file = open(infile.replace('.gaf','2.gaf'),'w')\n",
    "    for l in tqdm.tqdm(open(infile)):\n",
    "        if l.startswith('!'):\n",
    "            #new_file.write(l)\n",
    "            continue\n",
    "        else:    \n",
    "            temp_list = l.split('\\t')\n",
    "            code = l.split('\\t')[8]\n",
    "            if code not in  replace_dict:\n",
    "                continue\n",
    "            temp_list[8] = replace_dict[code]\n",
    "            new_file.write(temp_list[1]+'\\t'+temp_list[4]+'\\n')\n",
    "    new_file.close()\n",
    "\n",
    "pars_trytripDB_gaf('InData/TriTrypDB-46_TbruceiTREU927_GO.gaf')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obo_fname = download_go_basic_obo()\n",
    "in_go=os.path.join('InData/go-basic.obo')\n",
    "obodag = GODag(in_go)\n",
    "geneid2gos = read_associations('InData/TriTrypDB-46_TbruceiTREU927_GO2.gaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = out_df.index.values\n",
    "print(len(all_genes))\n",
    "goeaobj = GOEnrichmentStudy(\n",
    "            list(all_genes), # List of mouse protein-coding genes\n",
    "            geneid2gos, # geneid/GO associations\n",
    "            obodag, # Ontologies\n",
    "            propagate_counts = False,\n",
    "            alpha = 0.05, # default significance cut-off\n",
    "            methods = ['fdr_bh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = []\n",
    "def analysis(data, cluster_id=0):\n",
    "    geneids_study =  list(data[(data['label']==cluster_id)].index.values)\n",
    "    geneids_study = [n for n in geneids_study if n in all_genes]\n",
    "    goea_results_all = goeaobj.run_study(geneids_study)\n",
    "    goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.01]\n",
    "    for item in goea_results_sig:\n",
    "        item_list = str(item).split('\\t')\n",
    "        #print(item_list)\n",
    "        tempres = [str(cluster_id), item_list[0], str(item_list[6]), item_list[1], item_list[3], item_list[4]]\n",
    "        all_res.append('\\t'.join(tempres))\n",
    "\n",
    "for n in [1,2,3,4]:\n",
    "    print(n,'_________________')\n",
    "    analysis(X, cluster_id=n)\n",
    "\n",
    "print(len(all_res))    \n",
    "go_term_res = open('InData/goterm_enrich.txt','w')\n",
    "go_term_res.write('\\n'.join(all_res))\n",
    "go_term_res.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_terms = pd.read_csv('InData/goterm_enrich.txt', sep='\\t', header=None)\n",
    "go_terms.columns = ['clusterID','goID','pvalue','goType','goDesc','found']\n",
    "go_terms['found']=[int(n.split('/')[0]) for n in go_terms['found']]\n",
    "go_terms['clusterID'] = ['C'+str(n) for n in go_terms['clusterID']]\n",
    "print(go_terms.shape)\n",
    "go_terms = go_terms[go_terms['found']>=2]\n",
    "print(go_terms.shape)\n",
    "del go_terms['found']\n",
    "go_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_terms['clusterID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_go = go_terms.goID.value_counts()[go_terms.goID.value_counts()<=3].index.values\n",
    "go_terms = go_terms[go_terms.goID.isin(unique_go)]\n",
    "go_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_terms['clusterID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_terms = go_terms[go_terms['clusterID']!='C1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vizGo = pd.pivot_table(go_terms, index='goID',columns['clusterID'])#.reset_index()\n",
    "vizGo = pd.pivot_table(go_terms, index='goDesc', columns=['clusterID'])\n",
    "vizGo = -np.log10(vizGo)\n",
    "vizGo=vizGo.fillna(0)\n",
    "print(vizGo.head())\n",
    "vizGo.columns = ['C2','C3','C4']\n",
    "vizGo =vizGo.sort_values(['C2','C3','C4'])\n",
    "vizGo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizGo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO term Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del vizGo['C1']\n",
    "fig, ax = plt.subplots(figsize=(12,6))  \n",
    "cbar_ax = fig.add_axes([1, .1, .03, .2])\n",
    "# Sample figsize in inches\n",
    "sns.heatmap(vizGo,\n",
    "            cmap=sns.color_palette(\"Blues\", 128),\n",
    "           ax=ax, cbar_ax = cbar_ax, cbar=True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.set_title('GO Terms Enrichment')\n",
    "print(ax.get_ylim())\n",
    "ax.set_ylim(ax.get_ylim()[0]+0.5, 0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Figure_17.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bsub_genes = table_Bpol_v_Bsub[ (table_Bpol_v_Bsub['log_FDR']>2) & (table_Bpol_v_Bsub['logFC']<-2)]\n",
    "geneids_study =  Bsub_genes.index.values\n",
    "geneids_study = [n for n in geneids_study if n in all_genes]\n",
    "goea_results_all = goeaobj.run_study(geneids_study)\n",
    "goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.01]\n",
    "for item in goea_results_sig:\n",
    "    item_list = str(item).split('\\t')\n",
    "    print(item_list[0], str(item_list[6]), item_list[1],  item_list[4], item_list[5],item_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psub_genes = table_Ppol_v_Psub[ (table_Ppol_v_Psub['log_FDR']>2) & (table_Ppol_v_Psub['logFC']<-2)]\n",
    "geneids_study =  Psub_genes.index.values\n",
    "geneids_study = [n for n in geneids_study if n in all_genes]\n",
    "goea_results_all = goeaobj.run_study(geneids_study)\n",
    "goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.01]\n",
    "for item in goea_results_sig:\n",
    "    item_list = str(item).split('\\t')\n",
    "    print(item_list[0], str(item_list[6]), item_list[1],  item_list[4], item_list[5],item_list[3],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mRNA Half Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcf_hl = pd.read_csv('InData/mRNA_Half_Life/mrnaPCFhl.txt',sep='\\t',index_col=[0])\n",
    "bsf_hl = pd.read_csv('InData/mRNA_Half_Life/mrnaBSFhl.txt',sep='\\t',index_col=[0])\n",
    "hl = pcf_hl.join(bsf_hl,how='outer')\n",
    "hl=hl.reset_index()\n",
    "hl_lookup = pd.read_csv('InData/mRNA_Half_Life//mRNAhl_lookup.txt',sep='\\t',index_col=[0])\n",
    "hl_df = hl_lookup.merge(hl,left_on='Input ID',right_on='Gene_ID',how='outer')\n",
    "hl_df.set_index('Gene_ID',inplace=True)\n",
    "hl_df=hl_df.join(X,how='left')\n",
    "del hl_df['Unnamed: 6']\n",
    "#hl_df['hl_dif']=hl_df['BSF_half-life']/hl_df['PCF_half-life']\n",
    "hl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in ['PCF_half-life','BSF_half-life']:\n",
    "#    col_zscore = col + '_zscore'\n",
    "#    hl_df[col_zscore] =((hl_df[col] - hl_df[col].mean())/hl_df[col].std(ddof=0)).values\n",
    "\n",
    "#hl_df['hl_dif_zscore']=hl_df['BSF_half-life_zscore']-hl_df['PCF_half-life_zscore']    \n",
    "#hl_df.groupby('label')[['PCF_half-life_zscore','BSF_half-life_zscore','hl_dif_zscore']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table mRNA half life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_df['hl_dif']=hl_df['BSF_half-life']/hl_df['PCF_half-life']    \n",
    "hl_df.groupby('label')[['PCF_half-life','BSF_half-life','hl_dif']].median().sort_values('hl_dif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = hl_df[['BSF_half-life','label']]\n",
    "temp1.columns = ['half-life','cluster']\n",
    "temp1['life_stage']='BSF'\n",
    "temp2 = hl_df[['PCF_half-life','label']]\n",
    "temp2.columns = ['half-life','cluster']\n",
    "temp2['life_stage']='PCF'\n",
    "dataset_hl = pd.concat([temp1,temp2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))  \n",
    "sns.boxplot(data=dataset_hl,x='cluster',\n",
    "            y='half-life',hue='life_stage',\n",
    "            showfliers=False,ax=ax)\n",
    "plt.savefig('Figures/Figure_18.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hl.groupby(['cluster','life_stage'])['half-life'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein Abundance Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iBAQ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pro = []\n",
    "bsf_pro = pd.read_csv('InData/Proteomics/proteinGroups_BSF.zip',sep='\\t')\n",
    "bsf_pro = UT.clean_df(bsf_pro)\n",
    "bsf_pro['gene_ids'] = [UT.clean_id(n) for n in bsf_pro['Protein IDs']]\n",
    "bsf_pro = bsf_pro[['gene_ids','iBAQ H']]\n",
    "bsf_pro.columns = ['gene_ids','iBAQ BSF']\n",
    "bsf_pro.set_index('gene_ids',inplace=True)\n",
    "list_pro.append(bsf_pro)\n",
    "\n",
    "pcf_pro = pd.read_csv('InData/Proteomics/proteinGroups_PCF.zip',sep='\\t')\n",
    "pcf_pro = UT.clean_df(pcf_pro)\n",
    "pcf_pro['gene_ids'] = [UT.clean_id(n) for n in pcf_pro['Protein IDs']]\n",
    "pcf_pro = pcf_pro[['gene_ids','iBAQ H']]\n",
    "pcf_pro.columns = ['gene_ids','iBAQ PCF']\n",
    "pcf_pro.set_index('gene_ids',inplace=True)\n",
    "list_pro.append(pcf_pro)\n",
    "\n",
    "proteomic_df = pd.concat(list_pro,axis=1)\n",
    "#proteomic_df = np.log10(proteomic_df)\n",
    "proteomic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mRNA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df = cluster_dataset.copy()\n",
    "gene_df['bsf_tot'] = np.log10(gene_df[['B_tot_1','B_tot_2','B_tot_3']].median(axis=1))\n",
    "gene_df['pcf_tot'] = np.log10(gene_df[['P_tot_1','P_tot_2','P_tot_3']].median(axis=1))\n",
    "\n",
    "gene_df['bsf_TC'] = np.log2(gene_df[['B_pol_1','B_pol_2','B_pol_3']].median(axis=1)/\n",
    "                         gene_df[['B_sub_1','B_sub_2','B_sub_3']].median(axis=1) )\n",
    "\n",
    "gene_df['pcf_TC'] = np.log2(gene_df[['P_pol_1','P_pol_2','P_pol_3']].median(axis=1)/\n",
    "                         gene_df[['P_sub_1','P_sub_2','P_sub_3']].median(axis=1) )\n",
    "\n",
    "\n",
    "gene_df['bsf_SUB'] = np.log10(gene_df[['B_sub_1','B_sub_2','B_sub_3']].median(axis=1))\n",
    "\n",
    "gene_df['pcf_SUB'] = np.log10(gene_df[['P_sub_1','P_sub_2','P_sub_3']].median(axis=1))\n",
    "\n",
    "\n",
    "gene_df = gene_df[['bsf_tot','pcf_tot','bsf_TC','pcf_TC','bsf_SUB','pcf_SUB']]\n",
    "proteomic_df = proteomic_df.join(gene_df,how='left')\n",
    "proteomic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic_df = proteomic_df.join(hl_df[['PCF_half-life','BSF_half-life']],how='left')\n",
    "proteomic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Protein half-life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_turn = []\n",
    "bsf_turn = pd.read_csv('InData/Proteomics/Table 2.csv')\n",
    "bsf_turn.set_index('protein_id',inplace=True)\n",
    "bsf_turn = bsf_turn[['half_life']]\n",
    "bsf_turn.columns = ['BSF_half_life_p']\n",
    "list_turn.append(bsf_turn[['BSF_half_life_p']])\n",
    "\n",
    "pcf_turn = pd.read_csv('InData/Proteomics/Table 3.csv')\n",
    "pcf_turn.set_index('protein_id',inplace=True)\n",
    "pcf_turn = pcf_turn[['half_life']]\n",
    "pcf_turn.columns = ['PCF_half_life_p']\n",
    "list_turn.append(pcf_turn[['PCF_half_life_p']])\n",
    "turn_df = pd.concat(list_turn,axis=1)\n",
    "turn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomic_df = proteomic_df.join(turn_df,how='left')\n",
    "proteomic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_bsf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_bsf = proteomic_df[['iBAQ BSF','bsf_tot','bsf_TC','BSF_half-life','BSF_half_life_p','bsf_SUB']]\n",
    "ml_bsf.columns = ['ibaq_bsf','mRNA_bsf','TC_bsf','mRNA_hl_bsf','Prot_hl_bsf','SUB_bsf']\n",
    "ml_bsf['Prot_hl_bsf']=np.log10(ml_bsf['Prot_hl_bsf']*60)\n",
    "ml_bsf['mRNA_hl_bsf']=np.log10(ml_bsf['mRNA_hl_bsf'])\n",
    "ml_bsf['ibaq_bsf'] = np.log10(ml_bsf['ibaq_bsf'])\n",
    "\n",
    "ml_pcf = proteomic_df[['iBAQ PCF','pcf_tot','pcf_TC','PCF_half-life','PCF_half_life_p','pcf_SUB']]\n",
    "ml_pcf.columns = ['ibaq_pcf','mRNA_pcf','TC_pcf','mRNA_hl_pcf','Prot_hl_pcf','SUB_pcf']\n",
    "ml_pcf['Prot_hl_pcf']=np.log10(ml_pcf['Prot_hl_pcf']*60)\n",
    "ml_pcf['ibaq_pcf'] = np.log10(ml_pcf['ibaq_pcf'])\n",
    "ml_pcf['mRNA_hl_pcf']=np.log10(ml_pcf['mRNA_hl_pcf'])\n",
    "\n",
    "ml_df=pd.concat([ml_bsf,ml_pcf],axis=1)\n",
    "#print(ml_df.shape)\n",
    "#ml_df=ml_df.dropna()#.replace(-np.inf, np.nan).replace(np.inf, np.nan).fillna(ml_df.mean())\n",
    "print(ml_df.shape)\n",
    "ml_df.head()\n",
    "del ml_df['SUB_pcf']\n",
    "del ml_df['SUB_bsf']\n",
    "#ml_df.drop(['mRNA_bsf','mRNA_pcf'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "#test=test.dropna()\n",
    "def plot_line(x,y,ax):\n",
    "    linreg = sp.stats.linregress(x, y)\n",
    "    ax.plot(x, linreg.slope*x + linreg.intercept,alpha=0.5)\n",
    "    ax.text(0.1, 0.8, 'r2='+str(round(linreg.rvalue,2)), \n",
    "                               horizontalalignment='center',\n",
    "               verticalalignment='center',\n",
    "               transform=ax.transAxes,fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSF and PCF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_bsf = RandomForestRegressor(max_depth=5, random_state=0,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf=10,\n",
    "                            criterion='mse')\n",
    "\n",
    "\n",
    "\n",
    "X = ml_df.copy()\n",
    "X = X[[n for n in X.columns if 'bsf' in n]]\n",
    "X=X.dropna()\n",
    "print(X.shape)\n",
    "\n",
    "y=X['ibaq_bsf']\n",
    "X=X.drop(['ibaq_bsf'],axis=1)\n",
    "X.columns = [n.replace('_bsf','') for n in X.columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state =1976)\n",
    "regr_bsf.fit(X_train, y_train)\n",
    "y_pred = regr_bsf.predict(X_test)\n",
    "\n",
    "\n",
    "fig,axes=plt.subplots(figsize=(14,6),ncols=2)\n",
    "\n",
    "\n",
    "ax=axes[1]\n",
    "ax.plot(y_test,y_pred,'b.')\n",
    "plot_line(y_test,y_pred,ax)\n",
    "\n",
    "ax.set_xlabel('iBAQ')\n",
    "ax.set_ylabel('Prediction')\n",
    "ax.set_title('BSF')\n",
    "\n",
    "\n",
    "\n",
    "regr_pcf = RandomForestRegressor(max_depth=5, random_state=0,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf=10,\n",
    "                            criterion='mse')\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#regr_pcf = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "X = ml_df.copy()\n",
    "X = X[[n for n in X.columns if 'pcf' in n]]\n",
    "X=X.dropna()\n",
    "print(X.shape)\n",
    "\n",
    "y=X['ibaq_pcf']\n",
    "X=X.drop(['ibaq_pcf'],axis=1)\n",
    "X.columns = [n.replace('_pcf','') for n in X.columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state =1976)\n",
    "regr_pcf.fit(X_train, y_train)\n",
    "y_pred = regr_pcf.predict(X_test)\n",
    "\n",
    "ax=axes[0]\n",
    "ax.plot(y_test,y_pred,'b.')\n",
    "plot_line(y_test,y_pred,ax)\n",
    "ax.set_xlabel('iBAQ')\n",
    "ax.set_ylabel('Prediction')\n",
    "ax.set_title('PCF')\n",
    "\n",
    "UT.set_fig_label(axes[0],'A')\n",
    "UT.set_fig_label(axes[1],'B')\n",
    "\n",
    "plt.savefig('Figures/Figure_23.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSF Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = ml_df.copy()\n",
    "#X = X[[n for n in X.columns if 'bsf' in n]]\n",
    "#X_test_p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shap\n",
    "\n",
    "\n",
    "regr_bsf = RandomForestRegressor(max_depth=5, random_state=0,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf=10,\n",
    "                             criterion='mse')\n",
    "\n",
    "\n",
    "\n",
    "X = ml_df.copy()\n",
    "X = X[[n for n in X.columns if 'bsf' in n]]\n",
    "X=X.dropna()\n",
    "print(X.shape)\n",
    "\n",
    "y=X['ibaq_bsf']\n",
    "X=X.drop(['ibaq_bsf'],axis=1)\n",
    "X.columns = [n.replace('_bsf','') for n in X.columns]\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state =1976)\n",
    "regr_bsf.fit(X_train_b, y_train_b)\n",
    "print(X.columns)\n",
    "print(X_train_b.columns)\n",
    "print(X_test_b.columns)\n",
    "\n",
    "\n",
    "#explainer_bsf = shap.TreeExplainer(regr_bsf)\n",
    "#shap_values_bsf = explainer_bsf.shap_values(X_train_b)\n",
    "#shap.summary_plot(shap_values_bsf, X_train_b,show=False)\n",
    "#f = plt.gcf()\n",
    "#f.set_size_inches(12,6)\n",
    "#plt.title('BSF',fontsize=16)\n",
    "#plt.savefig('Fig13.png')\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    " \n",
    "result = permutation_importance(regr_bsf, X_test_b, y_test_b, \n",
    "                                n_repeats=50, random_state=0,scoring=make_scorer(r2_score))\n",
    "print(result.importances_mean)\n",
    "bsf_importance = pd.DataFrame(result.importances,index=X_test_b.columns)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "bsf_importance.T.plot(kind='box',ax=ax)\n",
    "plt.savefig('Figures/Figure_24.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCF feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shap\n",
    "\n",
    "\n",
    "regr_pcf = RandomForestRegressor(max_depth=5, random_state=0,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf=10,\n",
    "                            criterion='mse')\n",
    "\n",
    "\n",
    "\n",
    "X = ml_df.copy()\n",
    "X = X[[n for n in X.columns if 'pcf' in n]]\n",
    "X=X.dropna()\n",
    "X = X[X['TC_pcf']>-1]\n",
    "print(X.shape)\n",
    "\n",
    "y=X['ibaq_pcf']\n",
    "X=X.drop(['ibaq_pcf'],axis=1)\n",
    "X.columns = [n.replace('_pcf','') for n in X.columns]\n",
    "\n",
    "\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state =1976)\n",
    "regr_pcf.fit(X_train_p, y_train_p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#explainer_pcf = shap.TreeExplainer(regr_pcf)\n",
    "#shap_values_pcf = explainer_bsf.shap_values(X_train_p)\n",
    "#shap.summary_plot(shap_values_pcf, X_train_p,show=False)\n",
    "#f = plt.gcf()\n",
    "#f.set_size_inches(12,6)\n",
    "#plt.title('PCF',fontsize=16)\n",
    "#plt.savefig('Fig14.png')\n",
    "\n",
    "\n",
    "#features = list(X.columns)\n",
    "#importances = regr_pcf.feature_importances_\n",
    "#indices = np.argsort(importances)\n",
    "#plt.title('PCF')\n",
    "#plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "#plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "#plt.xlabel('Relative Importance')\n",
    "#plt.show()\n",
    "\n",
    "result = permutation_importance(regr_pcf, X_test_p, y_test_p, n_repeats=50, random_state=0,\n",
    "                                scoring=make_scorer(r2_score))\n",
    "print(result.importances_mean)\n",
    "pcf_importance = pd.DataFrame(result.importances,index=X_test_p.columns)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "pcf_importance.T.plot(kind='box',ax=ax)\n",
    "plt.savefig('Figures/Figure_25.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infile='proteomics/CDS/peptides.zip'\n",
    "#bsf_cds_pep = pd.read_csv(infile,sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bsf_cds_pep['Proteins'] =bsf_cds_pep['Proteins'].astype(str)\n",
    "#bsf_cds_pep['name'] = [n.split(';')[0] for n in bsf_cds_pep['Proteins']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding new protein coding genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gtf2bed < 'InData/tb927_3_ks_st_sc_st_tr.gtf' > 'tb927_3_ks_st_sc_st_tr.bed'\n",
    "!sort-bed < 'tb927_3_ks_st_sc_st_tr.bed' - > 'tb927_3_ks_st_sc_st_tr_sorted.bed'\n",
    "outfile = open('tb927_3_ks_st_sc_st_tr_sorted_filter.bed','w')\n",
    "for line in open('tb927_3_ks_st_sc_st_tr_sorted.bed'):\n",
    "    if 'KS17' in line:\n",
    "        outfile.write(line)\n",
    "    elif 'MSTRG' in line:\n",
    "        outfile.write(line)\n",
    "    elif 'TRY.' in line:\n",
    "        outfile.write(line)\n",
    "    else:\n",
    "        pass\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_peps(infile='proteomics/CDS/peptides.zip'):\n",
    "    bsf_cds_pep = pd.read_csv(infile,sep='\\t', usecols=\n",
    "                              ['Proteins','Reverse','Potential contaminant',\n",
    "                              'Start position', 'Sequence', 'End position'])\n",
    "    bsf_cds_pep['Proteins'] =bsf_cds_pep['Proteins'].astype(str)\n",
    "    bsf_cds_pep['Reverse'] = bsf_cds_pep['Reverse'].astype(str)\n",
    "    bsf_cds_pep = bsf_cds_pep[bsf_cds_pep['Reverse'] != '+' ]\n",
    "    bsf_cds_pep['Potential contaminant'] = bsf_cds_pep['Potential contaminant'].astype(str)\n",
    "    bsf_cds_pep = bsf_cds_pep[bsf_cds_pep['Potential contaminant'] != '+' ]\n",
    "    del bsf_cds_pep['Potential contaminant']\n",
    "    bsf_cds_pep['my_name'] = [n.split(';')[0] for n in bsf_cds_pep['Proteins']]\n",
    "    bsf_cds_pep['my_chro'] = [n.split('-')[0] for n in bsf_cds_pep['my_name']]\n",
    "    bsf_cds_pep['my_frame'] = [n.split('-')[1] for n in bsf_cds_pep['my_name']]\n",
    "    bsf_cds_pep['my_start'] = [n.split('-')[2] for n in bsf_cds_pep['my_name']]\n",
    "    bsf_cds_pep['my_end'] = [n.split('-')[3] for n in bsf_cds_pep['my_name']]\n",
    "\n",
    "    bsf_cds_pep['my_start']=bsf_cds_pep['my_start'].astype(int)\n",
    "    bsf_cds_pep['my_end']=bsf_cds_pep['my_end'].astype(int)\n",
    "\n",
    "    bsf_cds_pep['dif'] = bsf_cds_pep['my_start']-bsf_cds_pep['my_end']\n",
    "    bsf_cds_pep['new_start'] = bsf_cds_pep[['my_start','my_end']].min(axis=1).astype(int)\n",
    "    bsf_cds_pep['new_end'] = bsf_cds_pep[['my_start','my_end']].max(axis=1).astype(int)\n",
    "    return bsf_cds_pep\n",
    "\n",
    "bsf_cds_pep =  process_peps(infile='InData/Proteomics/peptides_bsf.zip')\n",
    "pcf_cds_pep = process_peps(infile='InData/Proteomics/peptides_pcf.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsf_cds_pep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsf_cds_pep=pd.concat([bsf_cds_pep,pcf_cds_pep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsf_cds_pep[['Start position','End position','Proteins','my_chro','my_start',\n",
    "             'my_end','new_start','new_end','dif','my_frame','Sequence']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsf_cds_pep[(bsf_cds_pep['my_chro']=='Tb927_10_v5.1')\n",
    "            &(bsf_cds_pep['my_start']>2944807)\n",
    "            &(bsf_cds_pep['my_end']<2945348)][['Start position','End position','Proteins','my_chro','my_start',\n",
    "             'my_end','new_start','new_end','dif','my_frame','Sequence']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get peptide genomic coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bsf_cds_pep = bk.copy()\n",
    "#bsf_cds_pep = bsf_cds_pep.head(50)\n",
    "starts = []\n",
    "ends = []\n",
    "for pep_start, pep_end, genomic_start, genomic_end, diff in zip(bsf_cds_pep['Start position'],bsf_cds_pep['End position'],\n",
    "                    bsf_cds_pep['my_start'],bsf_cds_pep['my_end'],bsf_cds_pep['dif']):\n",
    "    \n",
    "    \n",
    "    #e: difference, are in the + or - strand\n",
    "    #a: start of peptide sequence in the predicted protein\n",
    "    #b: end of peptide sequence in the predicted protein\n",
    "    #c: genomic start of the predicted protein\n",
    "    #b: genomic end of the predicted protein\n",
    "    \n",
    "    #the length of the predicted peptide sequence\n",
    "    pep_length = abs(pep_start-pep_end)*3\n",
    "    #print(pep_length)\n",
    "    #we are in the reverse strand\n",
    "    if diff > 0 :\n",
    "        #oddities with python starting to count at 0\n",
    "        #new_start = c-(b)+1\n",
    "        new_start = genomic_start-(pep_start*3)+3\n",
    "        new_end = new_start-pep_length-2 \n",
    "        \n",
    "    #we are in the forward strand\n",
    "    if diff < 0 :\n",
    "        #print('m here')\n",
    "        new_start = genomic_start+(pep_start*3)-3\n",
    "        #oddities with python starting to count at 0\n",
    "        new_end = new_start + pep_length +2\n",
    "        \n",
    "    starts.append(new_start)\n",
    "    ends.append(new_end)\n",
    "    #print(a,b,c,d,e,new_start,new_end)\n",
    "    \n",
    "    \n",
    "bsf_cds_pep['pep_start'] = starts\n",
    "bsf_cds_pep['pep_end'] = ends\n",
    "bsf_cds_pep['pep_start2'] = bsf_cds_pep[['pep_start','pep_end']].min(axis=1).astype(int)\n",
    "bsf_cds_pep['pep_end2'] = bsf_cds_pep[['pep_start','pep_end']].max(axis=1).astype(int)\n",
    "\n",
    "\n",
    "bsf_cds_pep['names']=(bsf_cds_pep['my_name']+'_'+\n",
    "                      bsf_cds_pep['pep_start2'].astype(str)+'-'+\n",
    "                      bsf_cds_pep['pep_end2'].astype(str)+'-'+bsf_cds_pep['Sequence']+'-bsf')\n",
    "\n",
    "\n",
    "bsf_cds_pep[['Start position','End position','Proteins','my_chro','my_start',\n",
    "             'my_end','new_start','new_end','dif','my_frame','Sequence',\n",
    "            'pep_start','pep_end','pep_start2','pep_end2','names','dif']].head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsf_cds_pep = bsf_cds_pep[['my_chro','pep_start2','pep_end2','names']]\n",
    "bsf_cds_pep = bsf_cds_pep[(bsf_cds_pep['pep_start2']>0)&(bsf_cds_pep['pep_end2']>0)]\n",
    "bsf_cds_pep.to_csv('pep_cds.bed', header=False, index=False,sep='\\t')\n",
    "bsf_cds_pep.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pep track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsf_cds_pep['dummy']=1\n",
    "bsf_cds_pep[['my_chro','pep_start2','pep_end2','dummy']\n",
    "           ].to_csv('all_pepe.bed',index=False,header=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find novel protein coding genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort-bed < 'pep_cds.bed' - > 'pep_cds_sorted.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bedextract  'pep_cds_sorted.bed' tb927_3_ks_st_sc_st_tr_sorted_filter.bed > cds.filtered.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bedtools intersect -wo -a tb927_3_ks_st_sc_st_tr_sorted_filter.bed \\\n",
    "                             -b cds.filtered.bed  > cds.filtered_closest2.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innew = pd.read_table('cds.filtered_closest2.bed',header=None)\n",
    "innew.columns = [\n",
    "    'chro','start','end','name','score','score2',\n",
    "    'ref','gene_feature','score3','gene_ref',\n",
    "    'chro2','pep_start','pep_end','pep_ref','pep_size'\n",
    "]\n",
    "innew=innew[innew['gene_feature']=='transcript']\n",
    "print(innew.groupby('name').size().shape)\n",
    "innew.groupby('name').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chrs = ['Tb927_{}_v5.1'.format(c) for c in ['01','02','03','04','05','06','07','08','09','10','11']]\n",
    "\n",
    "innew[innew['chro'].isin(main_chrs)].groupby(['chro','name']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(innew[innew['chro'].isin(main_chrs)].groupby('name').size().shape)\n",
    "innew[innew['chro'].isin(main_chrs)].groupby('name').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innew['dummy']=1\n",
    "innew[['chro2','pep_start','pep_end','dummy']].to_csv('new_genes.bed',index=False,header=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "chr_dict = {}\n",
    "fasta_sequences = SeqIO.parse(open('InData/tb927_3.fasta'),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    chr_dict[name]=sequence\n",
    "    \n",
    "def get_seq(X, chr_dict):\n",
    "    temp_seq = chr_dict[X['ref_chro']]\n",
    "    temp_seq = temp_seq[X['ref_start']+1:X['ref_end']]\n",
    "    return temp_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find closest 5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene(indata):\n",
    "    indata = indata[-1].split(';')\n",
    "    res = {}\n",
    "    #print(indata)\n",
    "    for n in indata:\n",
    "        if 'gene_id' in n:\n",
    "            n=n.strip()\n",
    "            res[n.split(' ')[0].strip()]=n.split(' ')[1].strip('\\\"').strip('\\'').strip()\n",
    "    #print(res)\n",
    "    return res['gene_id']\n",
    "\n",
    "inbed = pd.read_csv('tb927_3_ks_st_sc_st_tr_sorted.bed',sep='\\t')\n",
    "inbed.columns = ['chro','start','end','gene_id','a','orient','source','ftype','e','f']\n",
    "inbed=inbed[inbed['ftype']=='transcript']\n",
    "inbed =inbed.reset_index()\n",
    "del inbed['index']\n",
    "#inbed =inbed.reset_index()\n",
    "#inbed = inbed.set_index('gene_id')\n",
    "inbed['gene_plus1'] = inbed['gene_id'].shift(+1)\n",
    "inbed['gene_plus2'] = inbed['gene_id'].shift(+2)\n",
    "inbed['orient_plus1'] = inbed['orient'].shift(+1)\n",
    "inbed['orient_plus2'] = inbed['orient'].shift(+2)\n",
    "inbed['gene_minus1'] = inbed['gene_id'].shift(-1)\n",
    "inbed['orient_minus1'] = inbed['orient'].shift(-1)\n",
    "inbed['gene_minus2'] = inbed['gene_id'].shift(-2)\n",
    "inbed['orient_minus2'] = inbed['orient'].shift(-2)\n",
    "inbed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_list = inbed[(inbed['orient_minus1']=='+')#&\n",
    "     #inbed['gene_id'].isin(common_genes)&\n",
    "     #inbed['gene_minus1'].str.startswith('Tb')\n",
    "                \n",
    "                ][['gene_id','gene_minus1','orient_minus1']]\n",
    "\n",
    "rev_list = inbed[(inbed['orient_plus1']=='-')#&\n",
    "#      inbed['gene_id'].isin(common_genes)&\n",
    "     #inbed['gene_plus1'].str.startswith('Tb')\n",
    "                \n",
    "                ][['gene_id','gene_plus1','orient_plus1']]\n",
    "rev_list.columns = ['gene_id','reg_gene','orient']\n",
    "for_list.columns = ['gene_id','reg_gene','orient']\n",
    "merge_list = pd.concat([for_list,rev_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge_list.shape)\n",
    "merge_list.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSF and PCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pol_v_sub.loc[['KS17gene_1749a','KS17gene_4295a','KS17gene_3137a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulatory_df = merge_list[\n",
    "    (merge_list['gene_id'].str.startswith('KS')#)|\n",
    "    #(merge_list['gene_id'].str.startswith('TRY.'))|\n",
    "    #(merge_list['gene_id'].str.startswith('MSTRG.')\n",
    "    )\n",
    "].drop_duplicates('gene_id').set_index('gene_id').join(\n",
    "    table_pol_v_sub,how='inner').reset_index().rename({'index':'gene_id'},axis=1).drop_duplicates(\n",
    "    'reg_gene').set_index('reg_gene').join(table_pol_v_sub,how='inner',rsuffix='_reg').reset_index(\n",
    ").rename({'index':'reg_gene'},axis=1).set_index('gene_id')\n",
    "\n",
    "regulatory_df = regulatory_df[regulatory_df['reg_gene'].str.startswith('Tb')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulatory_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inbed = pd.read_csv('tb927_3_ks_st_sc_st_tr_sorted.bed',sep='\\t')\n",
    "#inbed.columns = ['chro','start','end','gene_id','a','orient','source','ftype','e','f']\n",
    "#inbed=inbed[inbed['ftype']=='transcript']\n",
    "#inbed.columns = ['ref_'+n for n in inbed.columns]\n",
    "#inbed=inbed.drop_duplicates(subset=['ref_gene_id'])\n",
    "#inbed.set_index('ref_gene_id',inplace=True)\n",
    "#inbed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regulatory_df = regulatory_df.join(inbed,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr = pd.read_csv('PTR.txt',sep='\\t')\n",
    "ptr = ptr.drop_duplicates('gene_id')\n",
    "#ptr.set_index('gene_id',inplace=True)\n",
    "ptr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regulatory_df.shape)\n",
    "regulatory_df=regulatory_df.reset_index().merge(\n",
    "    ptr, how='left', left_on='reg_gene', right_on='gene_id').drop(\n",
    "    'gene_id_y',axis=1).rename({'gene_id_x':'gene_ks',\n",
    "                               'reg_gene':'gene_sensitive'\n",
    "                               },axis=1).drop('orient',axis=1)\n",
    "\n",
    "regulatory_df.drop([n for n in regulatory_df.columns if 'log_' in n],axis=1,inplace=True)\n",
    "#regulatory_df.columns = [n.replace('_reg','_sensitive') for n in regulatory_df.columns]\n",
    "regulatory_df.drop([n for n in regulatory_df.columns if '_reg' in n],axis=1,inplace=True)\n",
    "print(regulatory_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulatory_df['desc']=[desc_dict.get(n,'none') for n in regulatory_df['gene_sensitive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = regulatory_df[ (regulatory_df['logFC']>0) &\n",
    "              (regulatory_df['logCPM']>1) & \n",
    "              (regulatory_df['FDR']<0.01) ]['reg_type']\n",
    "selected.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulatory_df['selected'] = [1 if n in selected.dropna().index.values else 0 for n in regulatory_df.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulatory_df.to_csv('Tables/Table_6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDS analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('InData/tb927_3_ks_counts_cds.txt',index_col=[0],comment='#',sep='\\t')\n",
    "data_col = df.columns[5:25]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "#indata = df[df['sumValues']>200][data_col]\n",
    "indata = df[data_col]\n",
    "indata.columns = [n.split('/')[0] for  n in indata.columns]\n",
    "indata.head()\n",
    "print(indata.shape)\n",
    "indata.reset_index(inplace=True)\n",
    "indata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = indata.groupby('Geneid').sum().reset_index()\n",
    "indata = indata.drop_duplicates('Geneid')\n",
    "#indata.set_index('Geneid',inplace=True)\n",
    "print(indata.shape)\n",
    "indata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i indata\n",
    "rownames(indata) <- indata$Geneid\n",
    "indata <- subset(indata, select = -c(Geneid))\n",
    "library(\"limma\") \n",
    "library(\"edgeR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "group <- factor(c(\n",
    "    'Btot','Btot','Btot',\n",
    "    'Bpol','Bpol','Bpol',\n",
    "    'Bsub','Bsub','Bsub',\n",
    "    'Ptot','Ptot','Ptot',\n",
    "    'Ppol','Ppol','Ppol',\n",
    "    'Psub','Psub','Psub'))\n",
    "y <- DGEList(counts=indata,group=group)\n",
    "keep <- filterByExpr(y)\n",
    "y <- y[keep,,keep.lib.sizes=FALSE]\n",
    "y <- calcNormFactors(y)\n",
    "design <- model.matrix(~group)\n",
    "y <- estimateDisp(y,design)\n",
    "cpm_df <- cpm(y)\n",
    "genes = row.names(y)\n",
    "head(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -o cpm_df,genes\n",
    "indata.set_index('Geneid',inplace=True)\n",
    "out_df = pd.DataFrame(cpm_df,index=genes,columns=indata.columns)\n",
    "\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcf_ribo = pd.read_csv('InData/PolisomeLiterature/PCF.csv',index_col=[0])\n",
    "pcf_ribo.columns = ['PCF_'+n for n in pcf_ribo.columns]\n",
    "bsf_ribo = pd.read_csv('InData/PolisomeLiterature/BSF.csv',index_col=[0])\n",
    "bsf_ribo.columns = ['BSF_'+n for n in bsf_ribo.columns]\n",
    "ribo = pcf_ribo.join(bsf_ribo,how='outer')\n",
    "ribo = ribo.reset_index()\n",
    "ribo=ribo.replace('#DIV/0!',np.nan)\n",
    "ribo_lookup = pd.read_csv('InData/PolisomeLiterature/GeneByLocusTag_Summary.txt',sep='\\t')\n",
    "ribo_lookup.head()\n",
    "ribo_df = ribo_lookup.merge(ribo,left_on='Input ID',right_on='2013Latest_numbers',how='outer')\n",
    "#hl_df.head()\n",
    "ribo_df.set_index('Gene ID',inplace=True)\n",
    "ribo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 6\n",
    "Antwi, et al., 2016\n",
    "\n",
    "without trimming the x-axes of BSF sample\n",
    "\n",
    "https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-016-2624-3/figures/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([ribo_df['BSF_Fraction in polysomes'].astype(float),\n",
    "                 ribo_df['PCF_Fraction in polysomes'].astype(float),\n",
    "                 np.log10(ribo_df['BSF_Ribosomes/kb BS'].astype(float)),\n",
    "                 np.log10(ribo_df['PCF_Ribosomes/kb'].astype(float))],axis=1)\n",
    "test=test.replace(-np.inf,np.nan).replace(np.inf,np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "def plot_line(x,y,ax):\n",
    "    linreg = sp.stats.linregress(x, y)\n",
    "    ax.plot(x, linreg.slope*x + linreg.intercept,alpha=0.5)\n",
    "    ax.text(0.2, 1, round(linreg.rvalue,2))\n",
    "\n",
    "fig,axes=plt.subplots(figsize=(12,6),ncols=2)\n",
    "ax=axes[1]\n",
    "x='BSF_Fraction in polysomes'\n",
    "y='BSF_Ribosomes/kb BS'\n",
    "test.plot(x=x,\n",
    "          y=y,kind='scatter',ax=ax,\n",
    "         alpha=0.1)\n",
    "plot_line(test[x],test[y],ax)\n",
    "ax=axes[0]\n",
    "x='PCF_Fraction in polysomes'\n",
    "y='PCF_Ribosomes/kb'\n",
    "test.plot(x='PCF_Fraction in polysomes',\n",
    "          y='PCF_Ribosomes/kb',kind='scatter',ax=ax,\n",
    "         alpha=0.1)\n",
    "plot_line(test[x],test[y],ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDdf2 = pd.concat([\n",
    "        #Traslation Competent BSF\n",
    "        ((out_df['B_pol_1']/0.7) / ((out_df['B_pol_1']/0.7) + (out_df['B_sub_1']/0.3))),\n",
    "        ((out_df['B_pol_2']/0.7) / ((out_df['B_pol_2']/0.7) + (out_df['B_sub_2']/0.3))),\n",
    "        ((out_df['B_pol_3']/0.7) / ((out_df['B_pol_3']/0.7) + (out_df['B_sub_3']/0.3))),\n",
    "        #Traslation Competent PCF\n",
    "        ((out_df['P_pol_1']/0.7) / ((out_df['P_pol_1']/0.7) + (out_df['P_sub_1']/0.3))),\n",
    "        ((out_df['P_pol_2']/0.7) / ((out_df['P_pol_2']/0.7) + (out_df['P_sub_2']/0.3))),\n",
    "        ((out_df['P_pol_3']/0.7) / ((out_df['P_pol_3']/0.7) + (out_df['P_sub_3']/0.3)))],\n",
    "        #BSF vs PCF\n",
    "         axis=1)\n",
    "\n",
    "\n",
    "TDdf2.columns = ['B1','B2','B3','P1','P2','P3']\n",
    "TDdf2['median_b']=TDdf2[['B1','B2','B3']].median(axis=1)\n",
    "TDdf2['median_p']=TDdf2[['P1','P2','P3']].median(axis=1)\n",
    "TDdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.join(TDdf2[['median_b','median_p']]).replace(-np.inf,np.nan).replace(np.inf,np.nan).dropna()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.dropna()\n",
    "\n",
    "fig,axes=plt.subplots(figsize=(12,6), ncols=2)\n",
    "\n",
    "x='median_b'\n",
    "y='BSF_Fraction in polysomes'\n",
    "test.plot(x=x,\n",
    "          y=y,kind='scatter',ax=axes[1],\n",
    "          alpha=0.1)\n",
    "UT.plot_line(test[x],test[y],axes[1])\n",
    "\n",
    "\n",
    "axes[1].set_title('Fraction in polysomes BSF')\n",
    "axes[1].set_xlim(0,1)\n",
    "axes[1].set_ylim(0,1)\n",
    "axes[1].set_ylabel('Antwi et al, 2016')\n",
    "axes[1].set_xlabel('This Study')\n",
    "\n",
    "\n",
    "x='median_p'\n",
    "y='PCF_Fraction in polysomes'\n",
    "test.plot(x=x,\n",
    "          y=y,kind='scatter',ax=axes[0],\n",
    "         alpha=0.1)\n",
    "UT.plot_line(test[x],test[y],axes[0])\n",
    "\n",
    "\n",
    "axes[0].set_title('Fraction in polysomes PCF')\n",
    "axes[0].set_xlim(0,1)\n",
    "axes[0].set_ylim(0,1)\n",
    "axes[0].set_ylabel('Antwi et al, 2016')\n",
    "axes[0].set_xlabel('This Study')\n",
    "\n",
    "plt.savefig('Figures/Figure_6.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## riboseq comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ribo_df = pd.read_csv('InData/ribo_counts_927.txt',sep='\\t',comment='#')\n",
    "ribo_df.columns = list(ribo_df.columns)[0:6]+['ribo_BSF','ribo_PCF']\n",
    "ribo_df[['ribo_BSF','ribo_PCF']]=np.log10(ribo_df[['ribo_BSF','ribo_PCF']])\n",
    "ribo_df.set_index('Geneid',inplace=True)\n",
    "ribo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['B_tot'] = out_df[['B_tot_1','B_tot_2','B_tot_3']].median(axis=1)\n",
    "out_df['P_tot'] = out_df[['P_tot_1','P_tot_2','P_tot_3']].median(axis=1)\n",
    "out_df['B_sub'] = out_df[['B_sub_1','B_sub_2','B_sub_3']].median(axis=1)\n",
    "out_df['P_sub'] = out_df[['P_sub_1','P_sub_2','P_sub_3']].median(axis=1)\n",
    "out_df['B_pol'] = out_df[['B_pol_1','B_pol_2','B_pol_3']].median(axis=1)\n",
    "out_df['P_pol'] = out_df[['P_pol_1','P_pol_2','P_pol_3']].median(axis=1)\n",
    "mydata = np.log10(out_df[['B_tot','B_sub','B_pol','P_tot','P_sub','P_pol']])\n",
    "mydata.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge=mydata.join(ribo_df,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge =merge.replace(-np.inf,np.nan).replace(np.inf,np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(ncols=3,nrows=2,figsize=(14,8))\n",
    "\n",
    "merge.plot(kind='scatter',x='B_pol',y='ribo_BSF',ax=axes[0,0], alpha=0.1, s=2)\n",
    "UT.plot_line(merge['B_pol'], merge['ribo_BSF'], axes[0,0],limits=(0,3))\n",
    "\n",
    "merge.plot(kind='scatter',x='B_tot',y='ribo_BSF',ax=axes[0,1], alpha=0.1, s=2)\n",
    "UT.plot_line(merge['B_tot'], merge['ribo_BSF'], axes[0,1],limits=(0,3))\n",
    "\n",
    "merge.plot(kind='scatter', x='B_sub', y='ribo_BSF',ax=axes[0,2], alpha=0.1, s=2)\n",
    "UT.plot_line(merge['B_sub'], merge['ribo_BSF'], axes[0,2],limits=(0,3))\n",
    "\n",
    "merge.plot(kind='scatter',x='P_pol',y='ribo_PCF',ax=axes[1,0], alpha=0.1, s=2)\n",
    "UT.plot_line(merge['P_pol'], merge['ribo_PCF'], axes[1,0],limits=(0,3))\n",
    "\n",
    "merge.plot(kind='scatter',x='P_tot',y='ribo_PCF',ax=axes[1,1], alpha=0.1, s=2)\n",
    "UT.plot_line(merge['P_tot'], merge['ribo_PCF'], axes[1,1],limits=(0,3))\n",
    "\n",
    "merge.plot(kind='scatter', x='P_sub', y='ribo_PCF',ax=axes[1,2], alpha=0.1, s=2)\n",
    "UT.plot_line(merge['P_sub'], merge['ribo_PCF'], axes[1,2],limits=(0,3))\n",
    "\n",
    "\n",
    "axes[0,0].set_title('BSF')\n",
    "axes[0,1].set_title('BSF')\n",
    "axes[0,2].set_title('BSF')\n",
    "axes[0,0].set_xlabel('')\n",
    "axes[0,1].set_xlabel('')\n",
    "axes[0,2].set_xlabel('')\n",
    "axes[0,0].set_ylabel('Ribosome')\n",
    "axes[0,1].set_ylabel('')\n",
    "axes[0,2].set_ylabel('')\n",
    "\n",
    "\n",
    "axes[1,0].set_title('PCF')\n",
    "axes[1,1].set_title('PCF')\n",
    "axes[1,2].set_title('PCF')\n",
    "axes[1,0].set_xlabel('Polysome')\n",
    "axes[1,1].set_xlabel('Total')\n",
    "axes[1,2].set_xlabel('Subpolysoma')\n",
    "axes[1,0].set_ylabel('Ribosome')\n",
    "axes[1,1].set_ylabel('')\n",
    "axes[1,2].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/Figure_7.png')\n",
    "#merge.plot(kind='scatter',x='B_tot',y='ribo_BSF')\n",
    "#merge.plot(kind='scatter',x='B_sub',y='ribo_BSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
